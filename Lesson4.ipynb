{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1\n",
    "Импортируйте библиотеки pandas и numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target, columns=['Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>23.6</td>\n",
       "      <td>28.648960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>32.4</td>\n",
       "      <td>36.495014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "      <td>15.411193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22.8</td>\n",
       "      <td>25.403213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.855280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_predict\n",
       "173    23.6  28.648960\n",
       "274    32.4  36.495014\n",
       "491    13.6  15.411193\n",
       "72     22.8  25.403213\n",
       "452    16.1  18.855280"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_table = pd.DataFrame({'y_test': y_test['Price'], 'y_predict': y_predict.flatten()})\n",
    "check_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112260057484912"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "Сделайте агрумент n_estimators равным 1000, max_depth должен быть равен 12 и random_state сделайте равным 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, \n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy, так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма. Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=12,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_RFR_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_RFR_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>23.6</td>\n",
       "      <td>22.846138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>32.4</td>\n",
       "      <td>31.156114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "      <td>16.297226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22.8</td>\n",
       "      <td>23.821036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>17.212148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_RFR_predict\n",
       "173    23.6      22.846138\n",
       "274    32.4      31.156114\n",
       "491    13.6      16.297226\n",
       "72     22.8      23.821036\n",
       "452    16.1      17.212148"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_RFR_table = pd.DataFrame({'y_test': y_test['Price'], 'y_RFR_predict': y_RFR_predict.flatten()})\n",
    "check_RFR_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8749965273218174"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_RFR_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n",
    "Коэффициент R2 на модели Случайный лес составил 0.875, а на линейной регрессии 0.711 => модель Random forest эффективнее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Задание 3\n",
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n",
    "\n",
    "С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "установите, какие два признака показывают наибольшую важность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03211748, 0.00154999, 0.0070941 , 0.0011488 , 0.01436832,\n",
       "       0.40270459, 0.01424477, 0.06403265, 0.00496762, 0.01169177,\n",
       "       0.01808961, 0.0123114 , 0.41567892])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41567892, 0.40270459])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#два последних (= максимальных по важности) значения в сортированном массиве из показателей значимости признаков\n",
    "feature_importance[feature_importance.argsort()[-1:-3:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LSTAT', 'RM'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наименование признаков с максимальной важностью\n",
    "X_train.columns[feature_importance.argsort()[-1:-3:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999994"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#найдите сумму всех показателей важности\n",
    "feature_importance.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Задание 4 датасет Credit Card Fraud Detection\n",
    "Для этого датасета мы будем решать задачу классификации - будем определять, какие из транзакциции по кредитной карте являются мошенническими. Мы будем вычислять AUC, то есть площадь под кривой ROC. Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split. Загрузите датасет creditcard.csv и создайте датафрейм df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:/python/creditcardfraud/creditcard.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.\n",
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.\n",
    "Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "pd.options.display.max_columns = 100. Просмотрите первые 10 строк датафрейма df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "X = df.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создайте объект Series под названием y из столбца Class.\n",
    "y = pd.Series(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split,\n",
    "используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199364, 30), (85443, 30), (199364,), (85443,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Просмотрите информацию о их форме.\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поиска по сетке параметров задайте такие параметры: parameters = [{'n_estimators': [10, 15], \n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5), 'max_depth': np.arange(4, 7)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_model = GridSearchCV(estimator=RandomForestClassifier(random_state=100),\n",
    "                             param_grid=parameters,\n",
    "                             scoring='roc_auc',\n",
    "                             cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=100, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'n_estimators': [10, 15], 'max_features': array([3, 4]), 'max_depth': array([4, 5, 6])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#строим модель RFC с полученными параметрами \n",
    "clf = RandomForestClassifier(n_estimators=15, max_depth=6, max_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features=3, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99392355e-01, 6.07644954e-04],\n",
       "       [9.99493397e-01, 5.06603453e-04],\n",
       "       [9.99722337e-01, 2.77662762e-04],\n",
       "       ...,\n",
       "       [9.99722337e-01, 2.77662762e-04],\n",
       "       [9.99438375e-01, 5.61625401e-04],\n",
       "       [8.61564597e-01, 1.38435403e-01]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba\n",
    "y_pred_proba = y_pred_proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00060764, 0.0005066 , 0.00027766, ..., 0.00027766, 0.00056163,\n",
       "       0.1384354 ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Из модуля sklearn.metrics импортируйте метрику roc_auc_score. Вычислите AUC на тестовых данных\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], c='grey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9504590982330006"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сравните с результатом, полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = y_pred_proba_train[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9771922974902604"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_pred_proba_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
